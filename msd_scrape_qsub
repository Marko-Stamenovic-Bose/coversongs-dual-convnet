#!/bin/bash
# qsub script to submit to nyu's scheduler
# submit with: qsub -l nodes=1:ppn=5,mem=4GB,walltime=48:00:00 msd_scrape_qsub

cd /scratch/mss460/msd/
# use -P processes to wget all sites on  sitelist
# with following args: 
# -A '*mp3' : discard anything not .mp3
# --tries 10 : 10 tries
# -w 0.2 --random-wait : random wait between 0 and 2*0.2 seconds
# -nc : no clobber, do not download already downloaded files
# -c : Continue getting a partially-downloaded file
# -r : recurse through subdirs
# -l 0 : recurse theough inf levels of subdirs
cat sitelist.txt | xargs -n 1 -P 4 wget --tries=10 -w .2 --random-wait -nc -c -A '*.mp3' -r -l 0 -nd
